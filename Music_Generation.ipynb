{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1  align=\"center\"> <b> Music Generator </b></h1>\n",
    "<h4 align=\"center\">By Sharoon Yaqub</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading Data \n",
    "\n",
    "url = 'http://hog.ee.columbia.edu/craffel/lmd/lmd_full.tar.gz'\n",
    "save_path = 'lmd_full.tar.gz'\n",
    "extract_path = 'lmd_full'\n",
    "\n",
    "print(\"Downloading LMD...\")\n",
    "urllib.request.urlretrieve(url, save_path)\n",
    "print(\"Download complete!\")\n",
    "\n",
    "print(\"Extracting LMD...\")\n",
    "with tarfile.open(save_path, 'r:gz') as tar:\n",
    "    tar.extractall(extract_path)\n",
    "print(\"Extraction complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data \n",
    "def load_notes(file_path):\n",
    "    midi = converter.parse(file_path)\n",
    "    notes = []\n",
    "\n",
    "    # Traverse all the elements in the MIDI file\n",
    "    for element in midi.flat:\n",
    "        if isinstance(element, note.Note):\n",
    "            notes.append(str(element.pitch))\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, sequence_length):\n",
    "    pitch_names = sorted(set(item for item in notes))\n",
    "    pitch_to_int = dict((pitch, idx) for idx, pitch in enumerate(pitch_names))\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # Create sequences of input notes and corresponding target notes\n",
    "    for i in range(len(notes) - sequence_length):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([pitch_to_int[pitch] for pitch in sequence_in])\n",
    "        network_output.append(pitch_to_int[sequence_out])\n",
    "\n",
    "    num_patterns = len(network_input)\n",
    "    input_data = np.reshape(network_input, (num_patterns, sequence_length, 1))\n",
    "    input_data = input_data / float(len(pitch_names))\n",
    "    output_data = np.array(network_output)\n",
    "\n",
    "    return input_data, output_data, pitch_names\n",
    "\n",
    "def generate_music(model, input_data, pitch_names, sequence_length, num_notes):\n",
    "    start = np.random.randint(0, len(input_data) - 1)\n",
    "    pattern = list(input_data[start])\n",
    "    prediction_output = []\n",
    "\n",
    "    # Generate notes\n",
    "    for _ in range(num_notes):\n",
    "        prediction_input = np.reshape(pattern, (1, sequence_length, 1))\n",
    "        prediction_input = prediction_input / float(len(pitch_names))\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "        index = np.argmax(prediction)\n",
    "        result = pitch_names[index]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:]\n",
    "\n",
    "    return prediction_output\n",
    "\n",
    "notes = load_notes('music.mid')\n",
    "\n",
    "sequence_length = 100\n",
    "num_notes = 500\n",
    "\n",
    "input_data, output_data, pitch_names = prepare_sequences(notes, sequence_length)\n",
    "\n",
    "# Define the RNN model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(input_data.shape[1], input_data.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(pitch_names), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "# Train the model\n",
    "model.fit(input_data, output_data, epochs=50, batch_size=64)\n",
    "\n",
    "generated_notes = generate_music(model, input_data, pitch_names, sequence_length, num_notes)\n",
    "\n",
    "midi_stream = stream.Stream()\n",
    "for pattern in generated_notes:\n",
    "    if '.' in pattern:\n",
    "        notes_in_chord = pattern.split('.')\n",
    "        chord_notes = []\n",
    "        for current_note in notes_in_chord:\n",
    "            new_note = note.Note(int(current_note))\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            chord_notes.append(new_note)\n",
    "        new_chord = chord.Chord(chord_notes)\n",
    "        midi_stream.append(new_chord)\n",
    "    else:\n",
    "        new_note = note.Note(int(pattern))\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        midi_stream.append(new_note)\n",
    "\n",
    "midi_stream.write('midi', fp='generated_music.mid')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
